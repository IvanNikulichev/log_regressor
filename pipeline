import numpy as np
from sklearn.base import RegressorMixin
from typing import Optional, Sequence, List
import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import StandardScaler

interesting_columns = ["Overall_Qual", "Garage_Qual", "Sale_Condition", "MS_Zoning"]

class OneHotPreprocessor(BaseDataPreprocessor):
    def __init__(self, **kwargs):
        super(OneHotPreprocessor, self).__init__(**kwargs)
        self.final_columns_ = None
        self.numerical_columns_ = None

    def fit(self, data, *args):
        if self.needed_columns is None:
            raise ValueError("needed_columns must be provided for OneHotPreprocessor")
        
        self.numerical_columns_ = [col for col in data.columns if col not in self.needed_columns]
        
        temp_encoded_df = pd.get_dummies(data, columns=self.needed_columns)
        
        self.final_columns_ = temp_encoded_df.columns.tolist()
        
        return self

    def transform(self, data):
        if self.final_columns_ is None:
            raise RuntimeError("Call fit before transform.")
            
        encoded_data = pd.get_dummies(data, columns=self.needed_columns)
        
        aligned_data = encoded_data.reindex(columns=self.final_columns_, axis=1, fill_value=0)
        
        return aligned_data.to_numpy()

class BaseDataPreprocessor(BaseEstimator, TransformerMixin):
    def __init__(self, needed_columns: Optional[Sequence[str]] = None):
        self.needed_columns = list(needed_columns) if needed_columns is not None else None
        self.scaler = StandardScaler()
        self.columns_: Optional[List[str]] = None

    def fit(self, data: pd.DataFrame, *args):
        if self.needed_columns is None:
            cols = list(data.columns)
        else:
            missing = [c for c in self.needed_columns if c not in data.columns]
            if missing:
                raise KeyError(f"Columns not found in DataFrame: {missing}")
            cols = list(self.needed_columns)
        self.columns_ = cols
        self.scaler.fit(data[self.columns_].to_numpy(dtype=float))
        return self

    def transform(self, data: pd.DataFrame) -> np.ndarray:
        if self.columns_ is None:
            raise RuntimeError("Call fit before transform.")
        missing = [c for c in self.columns_ if c not in data.columns]
        if missing:
            raise KeyError(f"Columns not found in DataFrame: {missing}")
        X = data[self.columns_].to_numpy(dtype=float)
        return self.scaler.transform(X)


class SGDLinearRegressor(RegressorMixin):
    def __init__(
        self,
        lr=0.011,
        regularization=1.0,
        delta_converged=1e-4,
        max_steps=100000,
        batch_size=128,
    ):
        self.lr = lr
        self.regularization = regularization
        self.max_steps = max_steps
        self.delta_converged = delta_converged
        self.batch_size = batch_size

        self.weights = None
        self.b = None

    def fit(self, X, Y):
        len_data, len_features = X.shape

        self.weights = np.zeros(len_features)
        self.b = 0.0

        for i in range(self.max_steps):
            weights_old = self.weights.copy()
            index = np.random.choice(len_data, size=self.batch_size)
            X_batch = X[index]
            Y_batch = Y[index]
            
            y_pred = X_batch @ self.weights + self.b
            error = y_pred - Y_batch
            grad_weights = (2 / self.batch_size) * X_batch.T @ error + 2 * self.regularization * self.weights
            grad_b = 2 * np.mean(error)
            self.weights -= self.lr * grad_weights
            self.b -= self.lr * grad_b
            if np.linalg.norm(self.weights - weights_old) < self.delta_converged:
                break
        self.coef_ = self.weights
        self.intercept_ = self.b
        return self


    def predict(self, X):
        return X @ self.coef_ + self.intercept_

def make_ultimate_pipeline():
    # <YOUR CODE HERE>
    pass

# Check yourself

model = SGDLinearRegressor()
model.fit(X_train, Y_train)

prediction = model.predict(X_test)
print(Y_test.shape, prediction.shape)
print("MAE : ", mean_absolute_error(Y_test, prediction))
print("Mean log : ", root_mean_squared_logarithmic_error(Y_test, prediction))



def make_ultimate_pipeline():
    from sklearn.compose import make_column_selector
    from sklearn.preprocessing import OneHotEncoder

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), make_column_selector(dtype_include=np.number)),
            ('cat', OneHotEncoder(handle_unknown='ignore'), make_column_selector(dtype_include=['object', 'category']))
        ],
        remainder='passthrough'
    )
    
    model = SGDLinearRegressor(regularization=1.0, lr=0.001)

    ultimate_pipeline = Pipeline([
        ('preprocessor', preprocessor), 
        ('model', model)                
    ])
    
    return ultimate_pipeline